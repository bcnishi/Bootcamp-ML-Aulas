{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNnCsdiBpKlz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics,svm\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from skimage.measure import regionprops\n",
        "from skimage.filters import threshold_otsu\n",
        "from sklearn.preprocessing import MaxAbsScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvt_1nG83FUC",
        "outputId": "dfd96ca2-635d-44f0-f97a-06988f29cbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(datadir, classes, img_size=100):\n",
        "    training_data = []\n",
        "    label = []\n",
        "    for classe in range(len(classes)):\n",
        "        path = os.path.join(datadir, classes[classe])\n",
        "        shufled_list  = list(os.listdir(path))\n",
        "        shuffle(shufled_list)\n",
        "        for img in shufled_list:\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
        "            unique = np.unique(img_array)\n",
        "            if len(unique) == 1:\n",
        "                continue\n",
        "            training_data.append(img_array)\n",
        "            label.append(classe)\n",
        "    return training_data , label"
      ],
      "metadata": {
        "id": "WByePWT2pWFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data , label = load_data('/content/drive/MyDrive/CV/geometric',['circle','square','star','triangle'])"
      ],
      "metadata": {
        "id": "Z046yi6HpWek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_fire = np.zeros(len(d_dir))\n",
        "l_dandelion = np.ones(len(dandelion_dir))\n",
        "l_rose = 2*np.ones(len(rose_dir))\n",
        "l_sunflower = 3*np.ones(len(sunflower_dir))\n",
        "l_tulip = 4*np.ones(len(tulip_dir))\n",
        "y = np.concatenate((l_daisy, l_dandelion, l_rose, l_sunflower, l_tulip))\n",
        "y = to_categorical(y, 5)"
      ],
      "metadata": {
        "id": "hCdvyuwCzGHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_contours_param(contour):\n",
        "    contour_area = contour[0].filled_area\n",
        "    contour_perimeter = contour[0].perimeter\n",
        "    contour_convex_area = contour[0].convex_area\n",
        "    diameter = contour[0].equivalent_diameter\n",
        "    return contour_area , contour_perimeter, contour_convex_area, diameter"
      ],
      "metadata": {
        "id": "HIo4NN1o3Z4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features_extraction(images):\n",
        "    features_list = []\n",
        "    for image in images:\n",
        "        thresh = threshold_otsu(image)\n",
        "        binary = np.array(image > thresh).astype(int)\n",
        "        white_pixel = np.where(binary > 0)\n",
        "        if len(white_pixel[0]) > 7000:\n",
        "            binary = abs(1-binary) # ajuste de imagens negativas\n",
        "        regions = regionprops(binary)\n",
        "        contour_area , contour_perimeter, contour_convex_area, diameter = get_contours_param(regions)\n",
        "        features_list.append([contour_area , contour_perimeter, contour_convex_area, diameter])\n",
        "    norm =  MaxAbsScaler()\n",
        "    norm.fit(features_list)\n",
        "    norm_features = norm.transform(features_list)\n",
        "    return norm_features"
      ],
      "metadata": {
        "id": "jQkaivfo3dI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = features_extraction(data)"
      ],
      "metadata": {
        "id": "lZOJUCJs3jgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_svm_model(train_data,label_train_data,test_data):\n",
        "    clf = svm.SVC(kernel='linear')\n",
        "    clf.fit(train_data, label_train_data)\n",
        "    predicted = clf.predict(test_data)\n",
        "    return predicted\n",
        "def generate_SGDC_model(train_data,label_train_data,test_data):\n",
        "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n",
        "    clf.fit(train_data, label_train_data)\n",
        "    predicted = clf.predict(test_data)\n",
        "    return predicted\n",
        "def generate_naive_bayes_model(train_data,label_train_data,test_data):\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(train_data, label_train_data)\n",
        "    predicted = gnb.predict(test_data)\n",
        "    return predicted\n",
        "def generate_decision_tree_model(train_data,label_train_data,test_data):\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "    clf = clf.fit(train_data, label_train_data)\n",
        "    predicted = clf.predict(test_data)\n",
        "    return predicted\n",
        "def generate_random_forest_model(X_train, y_train,test_data):\n",
        "    rfc = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features='auto', n_estimators=200)\n",
        "    rfc.fit(X_train,y_train)\n",
        "    predicted = rfc.predict(test_data)\n",
        "    return predicted\n",
        "def generate_MLP_model(X_train, y_train,test_data):\n",
        "    classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    predicted = classifier.predict(test_data)\n",
        "    return predicted\n",
        "def generate_knn_model(train_data,label_train_data,test_data):\n",
        "    knn = KNeighborsClassifier()\n",
        "    knn.fit(train_data,label_train_data)\n",
        "    predicted = knn.predict(test_data)\n",
        "    return predicted"
      ],
      "metadata": {
        "id": "6GOO7b9R3udF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_classifiers(train_data,label_train_data,test_data):\n",
        "    return generate_knn_model(train_data,label_train_data,test_data),\\\n",
        "    generate_MLP_model(train_data,label_train_data,test_data),\\\n",
        "    generate_SGDC_model(train_data,label_train_data,test_data),\\\n",
        "    generate_svm_model(train_data,label_train_data,test_data),\\\n",
        "    generate_decision_tree_model(train_data,label_train_data,test_data),\\\n",
        "    generate_naive_bayes_model(train_data,label_train_data,test_data),\\\n",
        "    generate_random_forest_model(train_data,label_train_data,test_data),\n"
      ],
      "metadata": {
        "id": "a3jXoKT33vOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.3)\n",
        "results = gen_classifiers(X_train, y_train,X_test)"
      ],
      "metadata": {
        "id": "rnEsBGxj3xaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(results[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "E85xwQ_3HuYG",
        "outputId": "5a4deaf8-36d0-4d34-f627-86aa20602ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([2, 1, 0, 3, 0, 1, 0, 0, 0, 3, 3, 3, 3, 2, 3, 1, 0, 2, 3, 2, 3, 0,\n",
              "       0, 1, 2, 1, 3, 2, 3, 2, 0, 0, 3, 2, 3, 1, 2, 3, 0, 0, 2, 1, 3, 0,\n",
              "       0, 1, 2, 0, 0, 2, 3, 2, 2, 2, 0, 3, 0, 0, 2, 0, 3, 0, 1, 1, 1, 2,\n",
              "       1, 2, 3, 3, 3, 2, 0, 2, 0, 1, 3, 2, 0, 3, 0, 2, 3, 2, 2, 1, 0, 0,\n",
              "       1, 0, 1, 2, 0, 2, 0, 1, 3, 2, 2, 0, 2, 3, 3, 2, 3, 0, 1, 0, 2, 2,\n",
              "       3, 0, 1, 0, 3, 2, 2, 3, 1, 3, 2, 2, 3, 3, 1, 2, 3, 2, 3, 3, 1, 1,\n",
              "       0, 2, 3, 1, 0, 0, 3, 2, 3, 0, 2, 3, 0, 2, 0, 2, 0, 0, 2, 0, 2, 1,\n",
              "       3, 1, 3, 2, 3, 0, 1, 2, 0, 1, 3, 3, 3, 2, 0, 2, 2, 0, 3, 2, 3, 2,\n",
              "       3, 2, 2, 1, 3, 0, 1, 3, 0, 0, 3, 0, 0, 2, 3, 1, 0, 1, 3, 1, 0, 3,\n",
              "       3, 0, 3, 1, 3, 2, 0, 1, 2, 2, 3, 3, 1, 3, 3, 1, 2, 3, 3, 2, 2, 0,\n",
              "       2, 2, 3, 1, 3, 0, 1, 0, 1, 3, 1, 3, 1, 1, 0, 2, 0, 1, 2, 3, 3, 2,\n",
              "       2, 1, 3, 1, 1, 0, 0, 0, 3, 0, 3, 1, 0, 0, 1, 0, 2, 0, 1, 3, 1, 3,\n",
              "       3, 3, 0, 2, 2, 3, 1, 0, 2, 3, 3, 2, 0, 1, 3, 0, 0, 2, 2, 1, 3, 2,\n",
              "       2, 0, 2, 3, 3, 0, 2, 3, 3, 3, 3, 0, 1, 3, 1, 2, 0, 0, 3, 3, 3, 1,\n",
              "       0, 0, 0, 3, 0, 0, 2, 3, 3, 1, 0, 1, 3, 1, 2, 3, 0, 3, 3, 0, 1, 3,\n",
              "       0, 3, 1, 1, 2, 3, 3, 2, 0, 2, 0, 0, 3, 0, 2, 2, 1, 2, 3, 2, 0, 3,\n",
              "       0, 3, 1, 3, 2, 3, 3, 3, 1, 3, 3, 2, 0, 2, 3, 2, 1, 2, 3, 1, 3, 1,\n",
              "       1, 2, 1, 0, 2, 0, 2, 0, 3, 0, 1, 3, 1, 0, 0, 2, 2, 2, 0, 3, 1, 2,\n",
              "       2, 2, 3, 3, 0, 2, 2, 3, 2, 2, 0, 1, 1, 1, 0, 2, 3, 0, 0, 3, 0, 2,\n",
              "       3, 0, 1, 1, 2, 1, 3, 3, 0, 0, 3, 3, 1, 1, 1, 3, 2, 2, 2, 2, 3, 3,\n",
              "       2, 2, 0, 3, 3, 2, 1, 2, 1, 2, 2, 3, 1, 2, 3, 3, 3, 3, 3, 3, 0, 3,\n",
              "       3, 2, 2, 3, 3, 0, 2, 0, 2, 1, 3, 0, 3, 3, 1, 3, 3, 1, 2, 0, 2, 3,\n",
              "       0, 3, 1, 0, 1, 2, 0, 1, 2, 0, 3, 2, 1, 3, 2, 3, 1, 1, 1, 2, 2, 0,\n",
              "       2, 3, 3, 3, 2, 0, 0, 0, 3, 2, 1, 2, 3, 1, 1, 2, 2, 2, 3, 3, 0, 2,\n",
              "       3, 3, 2, 2, 3, 2, 0, 2, 2, 3, 1, 1, 3, 0, 2, 2, 3, 1, 2, 3])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = ['KNN', 'MLP', 'SGDC', 'SVM', 'Árvore de Decisão', 'NB', 'RF']\n",
        "\n",
        "for i in range(len(models)):\n",
        "  print(models[i])\n",
        "  acc = metrics.accuracy_score(y_test,results[i])\n",
        "  recall = metrics.recall_score(y_test,results[i],average=None)\n",
        "  precision = metrics.precision_score(y_test,results[i],average=None,zero_division=1)\n",
        "  f1 = metrics.f1_score(y_test,results[i],average=None)\n",
        "  print('Acurácia: ', acc)\n",
        "  print('Recall: ', recall)\n",
        "  print('Precisão: ', precision)\n",
        "  print('F1-score: ', f1)\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxG1bHwfK3X8",
        "outputId": "f71ac5bf-9e5c-4a5b-e57f-c3004207b9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN\n",
            "Acurácia:  0.9708029197080292\n",
            "Recall:  [0.94615385 0.91346154 1.         1.        ]\n",
            "Precisão:  [0.95348837 0.93137255 1.         0.98224852]\n",
            "F1-score:  [0.94980695 0.9223301  1.         0.99104478]\n",
            "\n",
            "\n",
            "MLP\n",
            "Acurácia:  0.9963503649635036\n",
            "Recall:  [1.         0.98076923 1.         1.        ]\n",
            "Precisão:  [0.98484848 1.         1.         1.        ]\n",
            "F1-score:  [0.99236641 0.99029126 1.         1.        ]\n",
            "\n",
            "\n",
            "SGDC\n",
            "Acurácia:  0.6751824817518248\n",
            "Recall:  [0.6        0.         1.         0.86746988]\n",
            "Precisão:  [0.70909091 1.         0.83146067 0.55384615]\n",
            "F1-score:  [0.65       0.         0.90797546 0.67605634]\n",
            "\n",
            "\n",
            "SVM\n",
            "Acurácia:  0.6313868613138686\n",
            "Recall:  [0.47692308 0.         0.7972973  1.        ]\n",
            "Precisão:  [0.71264368 1.         1.         0.48396501]\n",
            "F1-score:  [0.57142857 0.         0.88721805 0.65225933]\n",
            "\n",
            "\n",
            "Árvore de Decisão\n",
            "Acurácia:  0.9288321167883211\n",
            "Recall:  [0.93846154 0.79807692 0.97297297 0.96385542]\n",
            "Precisão:  [0.91729323 0.88297872 0.97959184 0.91954023]\n",
            "F1-score:  [0.92775665 0.83838384 0.97627119 0.94117647]\n",
            "\n",
            "\n",
            "NB\n",
            "Acurácia:  0.5\n",
            "Recall:  [0.30769231 0.26923077 0.4527027  0.8373494 ]\n",
            "Precisão:  [0.75471698 0.33333333 1.         0.40406977]\n",
            "F1-score:  [0.43715847 0.29787234 0.62325581 0.54509804]\n",
            "\n",
            "\n",
            "RF\n",
            "Acurácia:  0.8886861313868614\n",
            "Recall:  [0.89230769 0.65384615 0.9527027  0.97590361]\n",
            "Precisão:  [0.93548387 0.86075949 1.         0.79411765]\n",
            "F1-score:  [0.91338583 0.7431694  0.97577855 0.87567568]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}